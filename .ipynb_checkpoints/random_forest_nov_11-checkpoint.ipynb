{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our libraries \n",
    "\n",
    "# Pandas and numpy for data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Seaborn / matplotlib for visualization \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function to split our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Helper fuctions to evaluate our model.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "\n",
    "# Import our Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# Import our Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import the trees from sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "# Helper functions to visualize our trees\n",
    "from sklearn.tree import plot_tree, export_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary_Color</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Intake_Date</th>\n",
       "      <th>Intake_Condition</th>\n",
       "      <th>Intake_Type</th>\n",
       "      <th>days_stayed</th>\n",
       "      <th>Primary_Color_encoded</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Intake_Condition_encoded</th>\n",
       "      <th>Intake_Type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRN TABBY</td>\n",
       "      <td>Spayed</td>\n",
       "      <td>6</td>\n",
       "      <td>12/19/18</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>799</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRN TABBY</td>\n",
       "      <td>Spayed</td>\n",
       "      <td>9</td>\n",
       "      <td>10/4/19</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>OWNER SURRENDER</td>\n",
       "      <td>760</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG TABBY</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>12</td>\n",
       "      <td>6/24/17</td>\n",
       "      <td>ILL MILD</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>685</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRN TABBY</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>8</td>\n",
       "      <td>7/13/17</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>666</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRAY TABBY</td>\n",
       "      <td>Spayed</td>\n",
       "      <td>8</td>\n",
       "      <td>5/10/17</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>661</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Primary_Color       Sex  Age Intake_Date Intake_Condition      Intake_Type  \\\n",
       "0     BRN TABBY    Spayed    6    12/19/18           NORMAL            STRAY   \n",
       "1     BRN TABBY    Spayed    9     10/4/19           NORMAL  OWNER SURRENDER   \n",
       "2     ORG TABBY  Neutered   12     6/24/17         ILL MILD            STRAY   \n",
       "3     BRN TABBY  Neutered    8     7/13/17           NORMAL            STRAY   \n",
       "4    GRAY TABBY    Spayed    8     5/10/17           NORMAL            STRAY   \n",
       "\n",
       "   days_stayed  Primary_Color_encoded  Sex_encoded  Intake_Condition_encoded  \\\n",
       "0          799                      5            3                        13   \n",
       "1          760                      5            3                        13   \n",
       "2          685                     22            2                         7   \n",
       "3          666                      5            2                        13   \n",
       "4          661                     16            3                        13   \n",
       "\n",
       "   Intake_Type_encoded  \n",
       "0                    3  \n",
       "1                    1  \n",
       "2                    3  \n",
       "3                    3  \n",
       "4                    3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/df_only_numeric_value_nov_05.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = ['Primary_Color_encoded', 'Sex_encoded',  \n",
    "                     'Intake_Condition_encoded', 'Intake_Type_encoded']\n",
    "\n",
    "dependent_variable = 'days_stayed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = OneVsRestClassifier(DecisionTreeClassifier(max_depth=2))\n",
    "\n",
    "# X = df[independent_variables]\n",
    "# y = df[dependent_variable]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Eval Model\n",
    "# accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "# print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "# precision = precision_score(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "# print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "# recall = recall_score(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "# print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "# f1 = f1_score(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "# print('F1 Score: %f' % f1)\n",
    "\n",
    "# # Calculate predicted probabilities\n",
    "# y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# # Keep only the proba for True\n",
    "# y_pred_proba = y_pred_proba[:, 1]\n",
    "\n",
    "# # Compute auc score\n",
    "# auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "# print('AUC Score: %f' % auc)\n",
    "\n",
    "# # Produce classification Report\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Plot Tree\n",
    "# # Note: Plotting trees for multi-class problems can be complex and may not provide clear visualizations\n",
    "# # You may want to visualize individual trees if you're dealing with a smaller number of classes\n",
    "# class_names = df[dependent_variable].unique()\n",
    "# plot_tree(model.estimators_[0], feature_names=independent_variables, class_names=class_names, filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.010050\n",
      "Precision Score: 0.010050\n",
      "Recall Score: 0.010050\n",
      "F1 Score: 0.010050\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00        10\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         7\n",
      "           6       0.02      0.05      0.02        19\n",
      "           7       0.05      0.13      0.07        15\n",
      "           8       0.05      0.06      0.05        17\n",
      "           9       0.00      0.00      0.00        10\n",
      "          10       0.00      0.00      0.00        11\n",
      "          11       0.00      0.00      0.00        10\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.02      0.08      0.04        13\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       0.00      0.00      0.00        10\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       0.00      0.00      0.00         6\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       0.00      0.00      0.00         8\n",
      "          22       0.00      0.00      0.00         9\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.00      0.00      0.00        10\n",
      "          25       0.00      0.00      0.00         9\n",
      "          26       0.00      0.00      0.00         2\n",
      "          27       0.00      0.00      0.00         9\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.07      0.14      0.09         7\n",
      "          35       0.00      0.00      0.00         3\n",
      "          36       0.00      0.00      0.00         6\n",
      "          37       0.00      0.00      0.00         4\n",
      "          38       0.00      0.00      0.00         5\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00         5\n",
      "          41       0.00      0.00      0.00         6\n",
      "          42       0.00      0.00      0.00         7\n",
      "          43       0.00      0.00      0.00         8\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         4\n",
      "          48       0.00      0.00      0.00         5\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         3\n",
      "          53       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         5\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         7\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         4\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         4\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         5\n",
      "          64       0.00      0.00      0.00         2\n",
      "          65       0.00      0.00      0.00         5\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         3\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.00      0.00      0.00         2\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         7\n",
      "          73       0.00      0.00      0.00         7\n",
      "          75       0.00      0.00      0.00         3\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       0.00      0.00      0.00         6\n",
      "          78       0.00      0.00      0.00         3\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         5\n",
      "          84       0.00      0.00      0.00         6\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.00      0.00      0.00         2\n",
      "          89       0.00      0.00      0.00         2\n",
      "          90       0.00      0.00      0.00         4\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         4\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         3\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         3\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         3\n",
      "          99       0.00      0.00      0.00         2\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         2\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         2\n",
      "         108       0.00      0.00      0.00         2\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         2\n",
      "         111       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         2\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         3\n",
      "         115       0.00      0.00      0.00         2\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         0\n",
      "         118       0.00      0.00      0.00         2\n",
      "         120       0.00      0.00      0.00         4\n",
      "         122       0.00      0.00      0.00         3\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       0.00      0.00      0.00         2\n",
      "         126       0.00      0.00      0.00         3\n",
      "         127       0.00      0.00      0.00         2\n",
      "         128       0.00      0.00      0.00         2\n",
      "         131       0.00      0.00      0.00         2\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         2\n",
      "         139       0.00      0.00      0.00         2\n",
      "         140       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         2\n",
      "         149       0.00      0.00      0.00         2\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         1\n",
      "         177       0.00      0.00      0.00         1\n",
      "         182       0.00      0.00      0.00         2\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         1\n",
      "         192       0.00      0.00      0.00         1\n",
      "         196       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00         5\n",
      "         213       0.00      0.00      0.00         1\n",
      "         216       0.00      0.00      0.00         2\n",
      "         224       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         0\n",
      "         257       0.00      0.00      0.00         1\n",
      "         268       0.00      0.00      0.00         1\n",
      "         271       0.00      0.00      0.00         1\n",
      "         277       0.00      0.00      0.00         0\n",
      "         280       0.00      0.00      0.00         1\n",
      "         305       0.00      0.00      0.00         1\n",
      "         327       0.00      0.00      0.00         0\n",
      "         331       0.00      0.00      0.00         1\n",
      "         337       0.00      0.00      0.00         1\n",
      "         345       0.00      0.00      0.00         0\n",
      "         366       0.00      0.00      0.00         1\n",
      "         390       0.00      0.00      0.00         0\n",
      "         409       0.00      0.00      0.00         0\n",
      "         434       0.00      0.00      0.00         1\n",
      "         530       0.00      0.00      0.00         1\n",
      "         660       0.00      0.00      0.00         1\n",
      "         799       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.01       597\n",
      "   macro avg       0.00      0.00      0.00       597\n",
      "weighted avg       0.00      0.01      0.01       597\n",
      "\n",
      "Skipping ROC AUC calculation for class 149 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 153 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 158 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 162 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 185 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 213 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 224 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 257 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 280 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 331 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 337 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 434 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 530 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 660 as it is not present in the model.\n",
      "Skipping ROC AUC calculation for class 799 as it is not present in the model.\n",
      "Class 0 ROC AUC Score: 0.46302521008403363\n",
      "Class 1 ROC AUC Score: 0.562331081081081\n",
      "Class 2 ROC AUC Score: 0.407312925170068\n",
      "Class 3 ROC AUC Score: 0.4900340715502556\n",
      "Class 4 ROC AUC Score: 0.5656357388316151\n",
      "Class 5 ROC AUC Score: 0.4514527845036319\n",
      "Class 6 ROC AUC Score: 0.4155891458750683\n",
      "Class 7 ROC AUC Score: 0.6285796105383734\n",
      "Class 8 ROC AUC Score: 0.5939655172413794\n",
      "Class 9 ROC AUC Score: 0.5864565587734243\n",
      "Class 10 ROC AUC Score: 0.41894197952218426\n",
      "Class 11 ROC AUC Score: 0.6765758091993186\n",
      "Class 12 ROC AUC Score: 0.4289493575207861\n",
      "Class 13 ROC AUC Score: 0.5810721812434141\n",
      "Class 14 ROC AUC Score: 0.4653133903133903\n",
      "Class 15 ROC AUC Score: 0.48884156729131184\n",
      "Class 16 ROC AUC Score: 0.6049747048903878\n",
      "Class 17 ROC AUC Score: 0.7855329949238579\n",
      "Class 18 ROC AUC Score: 0.5861678004535147\n",
      "Class 19 ROC AUC Score: 0.43707555178268254\n",
      "Class 20 ROC AUC Score: 0.47198641765704585\n",
      "Class 21 ROC AUC Score: 0.4633913412563667\n",
      "Class 22 ROC AUC Score: 0.375\n",
      "Class 23 ROC AUC Score: 0.4306295399515738\n",
      "Class 24 ROC AUC Score: 0.6083475298126064\n",
      "Class 25 ROC AUC Score: 0.5051965230536659\n",
      "Class 26 ROC AUC Score: 0.6533613445378151\n",
      "Class 27 ROC AUC Score: 0.759920634920635\n",
      "Class 28 ROC AUC Score: 0.4593908629441625\n",
      "Class 29 ROC AUC Score: 0.5160202360876898\n",
      "Class 30 ROC AUC Score: 0.753781512605042\n",
      "Class 31 ROC AUC Score: 0.32802013422818793\n",
      "Class 32 ROC AUC Score: 0.5121065375302662\n",
      "Class 33 ROC AUC Score: 0.3884228187919463\n",
      "Class 34 ROC AUC Score: 0.5400726392251816\n",
      "Class 35 ROC AUC Score: 0.35185185185185186\n",
      "Class 36 ROC AUC Score: 0.48336153412295546\n",
      "Class 37 ROC AUC Score: 0.544266441821248\n",
      "Class 38 ROC AUC Score: 0.4998310810810811\n",
      "Class 39 ROC AUC Score: 0.5331081081081082\n",
      "Class 40 ROC AUC Score: 0.5152027027027026\n",
      "Class 41 ROC AUC Score: 0.4990129723632262\n",
      "Class 42 ROC AUC Score: 0.4432203389830508\n",
      "Class 43 ROC AUC Score: 0.34295415959252973\n",
      "Class 44 ROC AUC Score: 0.44285714285714284\n",
      "Class 45 ROC AUC Score: 0.4107744107744108\n",
      "Class 46 ROC AUC Score: 0.9723154362416108\n",
      "Class 47 ROC AUC Score: 0.4308600337268128\n",
      "Class 48 ROC AUC Score: 0.5052364864864864\n",
      "Class 49 ROC AUC Score: 0.4926222596964587\n",
      "Class 50 ROC AUC Score: 0.6226890756302521\n",
      "Class 51 ROC AUC Score: 0.43529411764705883\n",
      "Class 52 ROC AUC Score: 0.3939393939393939\n",
      "Class 53 ROC AUC Score: 0.9773489932885906\n",
      "Class 54 ROC AUC Score: 0.43456375838926176\n",
      "Class 55 ROC AUC Score: 0.7469594594594596\n",
      "Class 56 ROC AUC Score: 0.39681208053691275\n",
      "Class 57 ROC AUC Score: 0.4812348668280872\n",
      "Class 58 ROC AUC Score: 0.9035234899328859\n",
      "Class 59 ROC AUC Score: 0.5853709949409781\n",
      "Class 60 ROC AUC Score: 0.43456375838926176\n",
      "Class 61 ROC AUC Score: 0.5680860033726812\n",
      "Class 62 ROC AUC Score: 0.426890756302521\n",
      "Class 63 ROC AUC Score: 0.5212837837837838\n",
      "Class 64 ROC AUC Score: 0.3915966386554622\n",
      "Class 65 ROC AUC Score: 0.4079391891891892\n",
      "Class 66 ROC AUC Score: 0.38758389261744963\n",
      "Class 67 ROC AUC Score: 0.4504201680672269\n",
      "Class 68 ROC AUC Score: 0.6021324354657687\n",
      "Class 69 ROC AUC Score: 0.3764705882352941\n",
      "Class 70 ROC AUC Score: 0.6420168067226891\n",
      "Class 71 ROC AUC Score: 0.40184563758389263\n",
      "Class 72 ROC AUC Score: 0.5296610169491525\n",
      "Class 73 ROC AUC Score: 0.4364406779661017\n",
      "Class 75 ROC AUC Score: 0.42087542087542085\n",
      "Class 76 ROC AUC Score: 0.6676470588235294\n",
      "Class 77 ROC AUC Score: 0.5933446136491821\n",
      "Class 78 ROC AUC Score: 0.5521885521885521\n",
      "Class 79 ROC AUC Score: 0.4722222222222222\n",
      "Class 81 ROC AUC Score: 0.4412751677852349\n",
      "Class 82 ROC AUC Score: 0.7516835016835016\n",
      "Class 83 ROC AUC Score: 0.6989864864864864\n",
      "Class 84 ROC AUC Score: 0.4433164128595601\n",
      "Class 85 ROC AUC Score: 0.7050420168067226\n",
      "Class 86 ROC AUC Score: 0.438758389261745\n",
      "Class 87 ROC AUC Score: 0.4857142857142857\n",
      "Class 88 ROC AUC Score: 0.4470588235294118\n",
      "Class 89 ROC AUC Score: 0.47983193277310926\n",
      "Class 90 ROC AUC Score: 0.7048903878583473\n",
      "Class 91 ROC AUC Score: 0.46812080536912754\n",
      "Class 92 ROC AUC Score: 0.5645025295109611\n",
      "Class 94 ROC AUC Score: 0.6240179573512906\n",
      "Class 95 ROC AUC Score: 0.4488255033557047\n",
      "Class 96 ROC AUC Score: 0.4436026936026936\n",
      "Class 97 ROC AUC Score: 0.4764705882352941\n",
      "Class 98 ROC AUC Score: 0.5698653198653199\n",
      "Class 99 ROC AUC Score: 0.4042016806722689\n",
      "Class 100 ROC AUC Score: 0.4512605042016807\n",
      "Class 101 ROC AUC Score: 0.4639261744966443\n",
      "Class 102 ROC AUC Score: 0.39681208053691275\n",
      "Class 103 ROC AUC Score: 0.4605042016806723\n",
      "Class 104 ROC AUC Score: 0.419327731092437\n",
      "Class 105 ROC AUC Score: 0.450503355704698\n",
      "Class 106 ROC AUC Score: 0.4874161073825503\n",
      "Class 107 ROC AUC Score: 0.473109243697479\n",
      "Class 108 ROC AUC Score: 0.45966386554621846\n",
      "Class 109 ROC AUC Score: 0.4597315436241611\n",
      "Class 110 ROC AUC Score: 0.4781512605042017\n",
      "Class 111 ROC AUC Score: 0.4639261744966443\n",
      "Class 112 ROC AUC Score: 0.3915966386554622\n",
      "Class 113 ROC AUC Score: 0.3976510067114094\n",
      "Class 114 ROC AUC Score: 0.4814814814814815\n",
      "Class 115 ROC AUC Score: 0.4512605042016807\n",
      "Class 118 ROC AUC Score: 0.4403361344537815\n",
      "Class 120 ROC AUC Score: 0.43591905564924116\n",
      "Class 122 ROC AUC Score: 0.4671717171717172\n",
      "Class 123 ROC AUC Score: 0.4790268456375839\n",
      "Class 124 ROC AUC Score: 0.49747899159663866\n",
      "Class 125 ROC AUC Score: 0.47478991596638653\n",
      "Class 126 ROC AUC Score: 0.4671717171717172\n",
      "Class 127 ROC AUC Score: 0.48487394957983193\n",
      "Class 128 ROC AUC Score: 0.43445378151260505\n",
      "Class 131 ROC AUC Score: 0.44621848739495795\n",
      "Class 136 ROC AUC Score: 0.4697986577181208\n",
      "Class 137 ROC AUC Score: 0.48406040268456374\n",
      "Class 138 ROC AUC Score: 0.49831932773109244\n",
      "Class 139 ROC AUC Score: 0.7411764705882352\n",
      "Class 140 ROC AUC Score: 0.49161073825503354\n",
      "Class 143 ROC AUC Score: 0.4983221476510067\n",
      "Class 144 ROC AUC Score: 0.47063758389261745\n",
      "Class 146 ROC AUC Score: 0.45805369127516776\n",
      "Class 148 ROC AUC Score: 0.49495798319327733\n",
      "Class 149 ROC AUC Score: 0.4773489932885906\n",
      "Class 151 ROC AUC Score: 0.47986577181208057\n",
      "Class 152 ROC AUC Score: 0.4848993288590604\n",
      "Class 153 ROC AUC Score: 0.47315436241610737\n",
      "Class 158 ROC AUC Score: 0.4949664429530201\n",
      "Class 161 ROC AUC Score: 0.4966442953020134\n",
      "Class 162 ROC AUC Score: 0.7340336134453781\n",
      "Class 171 ROC AUC Score: 0.4513422818791946\n",
      "Class 174 ROC AUC Score: 0.4865771812080537\n",
      "Class 177 ROC AUC Score: 0.4697986577181208\n",
      "Class 182 ROC AUC Score: 0.48070469798657717\n",
      "Class 184 ROC AUC Score: 0.4790268456375839\n",
      "Class 185 ROC AUC Score: 0.4773489932885906\n",
      "Class 188 ROC AUC Score: 0.4874161073825503\n",
      "Class 192 ROC AUC Score: 0.47719594594594594\n",
      "Class 196 ROC AUC Score: 0.48487394957983193\n",
      "Class 199 ROC AUC Score: 0.4949664429530201\n",
      "Class 202 ROC AUC Score: 0.9739932885906041\n",
      "Class 203 ROC AUC Score: 0.49580536912751677\n",
      "Class 210 ROC AUC Score: 0.4848993288590604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinorahgarciavasquez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dinorahgarciavasquez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dinorahgarciavasquez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dinorahgarciavasquez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dinorahgarciavasquez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dinorahgarciavasquez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=100)  # You can adjust the number of estimators as needed\n",
    "\n",
    "X = df[independent_variables]\n",
    "y = df[dependent_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Now let's evaluate our model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average='micro', zero_division=1)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average='micro', zero_division=1)\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "\n",
    "# Calculate predicted probabilities\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Produce classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate ROC AUC score for each class separately in multiclass classification\n",
    "roc_auc_scores = []\n",
    "unique_classes = np.unique(y_test)\n",
    "for i in unique_classes:\n",
    "    # Check if there is more than one class\n",
    "    if len(unique_classes) > 1 and len(model.classes_) > 1:\n",
    "        if i in model.classes_:\n",
    "            # Get the column index corresponding to the current class\n",
    "            col_idx = np.where(model.classes_ == i)[0][0]\n",
    "            roc_auc_i = roc_auc_score(y_true=(y_test == i), y_score=y_pred_proba[:, col_idx], multi_class='ovr')\n",
    "            roc_auc_scores.append(roc_auc_i)\n",
    "        else:\n",
    "            print(f\"Skipping ROC AUC calculation for class {i} as it is not present in the model.\")\n",
    "    else:\n",
    "        print(f\"Skipping ROC AUC calculation for class {i} due to only one class present.\")\n",
    "\n",
    "# Print or use the ROC AUC scores as needed\n",
    "for i, roc_auc_i in zip(unique_classes, roc_auc_scores):\n",
    "    print(f'Class {i} ROC AUC Score: {roc_auc_i}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Primary_Color_encoded       0.555689\n",
       "Intake_Condition_encoded    0.239319\n",
       "Intake_Type_encoded         0.108832\n",
       "Sex_encoded                 0.096160\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets look at our feature importances\n",
    "feature_imp = pd.Series(model.feature_importances_,index=independent_variables).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
