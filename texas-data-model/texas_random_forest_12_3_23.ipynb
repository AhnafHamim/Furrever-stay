{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our libraries \n",
    "\n",
    "# Pandas and numpy for data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Seaborn / matplotlib for visualization \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function to split our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Helper fuctions to evaluate our model.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "\n",
    "# Import our Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# Import our Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import the trees from sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "# Helper functions to visualize our trees\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "\n",
    "#tree regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# imbalanced-learn library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>sex_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>CoatColor</th>\n",
       "      <th>CoatPattern</th>\n",
       "      <th>age_intake_months</th>\n",
       "      <th>stay_length</th>\n",
       "      <th>intake_type_encoded</th>\n",
       "      <th>intake_condition_encoded</th>\n",
       "      <th>sex_intake_encoded</th>\n",
       "      <th>breed_encoded</th>\n",
       "      <th>CoatColor_encoded</th>\n",
       "      <th>CoatPattern_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic_Shorthair_Mix</td>\n",
       "      <td>Black</td>\n",
       "      <td>Solid</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Other</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner_Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic_Shorthair_Mix</td>\n",
       "      <td>White_Mix</td>\n",
       "      <td>Solid</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic_Shorthair_Mix</td>\n",
       "      <td>Black</td>\n",
       "      <td>Solid</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intake_type intake_condition sex_intake                   breed  \\\n",
       "0            Stray           Normal     Female  Domestic_Shorthair_Mix   \n",
       "1            Stray           Normal       Male                   Other   \n",
       "2            Stray           Normal       Male                   Other   \n",
       "3  Owner_Surrender           Normal     Female  Domestic_Shorthair_Mix   \n",
       "4            Stray           Normal       Male  Domestic_Shorthair_Mix   \n",
       "\n",
       "   CoatColor CoatPattern  age_intake_months  stay_length  intake_type_encoded  \\\n",
       "0      Black       Solid                  1           31                    2   \n",
       "1      Brown       Other                 36            3                    2   \n",
       "2      Brown       Tabby                  1           68                    2   \n",
       "3  White_Mix       Solid                  1           24                    1   \n",
       "4      Black       Solid                  1           30                    2   \n",
       "\n",
       "   intake_condition_encoded  sex_intake_encoded  breed_encoded  \\\n",
       "0                         3                   0              1   \n",
       "1                         3                   1              2   \n",
       "2                         3                   1              2   \n",
       "3                         3                   0              1   \n",
       "4                         3                   1              1   \n",
       "\n",
       "   CoatColor_encoded  CoatPattern_encoded  \n",
       "0                  0                    1  \n",
       "1                  3                    0  \n",
       "2                  3                    2  \n",
       "3                  9                    1  \n",
       "4                  0                    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../texas_dataset/texas_level_encoded_numeric_value_dec_3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are predicting if a cat will stay more than a month in the shelter (yes = 1, no =0) â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11157"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['stay_length']>30).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14648"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['stay_length']<30).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>sex_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>CoatColor</th>\n",
       "      <th>CoatPattern</th>\n",
       "      <th>age_intake_months</th>\n",
       "      <th>stay_length</th>\n",
       "      <th>intake_type_encoded</th>\n",
       "      <th>intake_condition_encoded</th>\n",
       "      <th>sex_intake_encoded</th>\n",
       "      <th>breed_encoded</th>\n",
       "      <th>CoatColor_encoded</th>\n",
       "      <th>CoatPattern_encoded</th>\n",
       "      <th>stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26074</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic_Shorthair_Mix</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26075</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic_Shorthair</td>\n",
       "      <td>White_Mix</td>\n",
       "      <td>Solid</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26076</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Neonatal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic_Shorthair</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26077</th>\n",
       "      <td>Owner_Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic_Shorthair</td>\n",
       "      <td>Calico_or_Calico_mix</td>\n",
       "      <td>Solid</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26078</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic_Shorthair</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           intake_type intake_condition sex_intake                   breed  \\\n",
       "26074            Stray           Normal     Female  Domestic_Shorthair_Mix   \n",
       "26075            Stray           Normal       Male      Domestic_Shorthair   \n",
       "26076            Stray         Neonatal       Male      Domestic_Shorthair   \n",
       "26077  Owner_Surrender           Normal     Female      Domestic_Shorthair   \n",
       "26078            Stray           Normal     Female      Domestic_Shorthair   \n",
       "\n",
       "                  CoatColor CoatPattern  age_intake_months  stay_length  \\\n",
       "26074                 Brown       Tabby                  1            6   \n",
       "26075             White_Mix       Solid                 11           16   \n",
       "26076                 Brown       Tabby                  0           75   \n",
       "26077  Calico_or_Calico_mix       Solid                 36            7   \n",
       "26078                  Blue       Tabby                  1           31   \n",
       "\n",
       "       intake_type_encoded  intake_condition_encoded  sex_intake_encoded  \\\n",
       "26074                    2                         3                   0   \n",
       "26075                    2                         3                   1   \n",
       "26076                    2                         2                   1   \n",
       "26077                    1                         3                   0   \n",
       "26078                    2                         3                   0   \n",
       "\n",
       "       breed_encoded  CoatColor_encoded  CoatPattern_encoded  stay  \n",
       "26074              1                  3                    2     0  \n",
       "26075              0                  9                    1     0  \n",
       "26076              0                  3                    2     1  \n",
       "26077              0                  4                    1     0  \n",
       "26078              0                  2                    2     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this part is to predict long or short stay (0,1)\n",
    "import pandas as pd\n",
    "\n",
    "def categorize_stay(days_stayed):\n",
    "    if days_stayed <= 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame and \"days_stayed\" is the column you want to categorize\n",
    "df['stay'] = df['stay_length'].apply(categorize_stay)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>sex_intake</th>\n",
       "      <th>breed</th>\n",
       "      <th>CoatColor</th>\n",
       "      <th>CoatPattern</th>\n",
       "      <th>age_intake_months</th>\n",
       "      <th>stay_length</th>\n",
       "      <th>intake_type_encoded</th>\n",
       "      <th>intake_condition_encoded</th>\n",
       "      <th>sex_intake_encoded</th>\n",
       "      <th>breed_encoded</th>\n",
       "      <th>CoatColor_encoded</th>\n",
       "      <th>CoatPattern_encoded</th>\n",
       "      <th>stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic_Shorthair_Mix</td>\n",
       "      <td>Black</td>\n",
       "      <td>Solid</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Other</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner_Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Domestic_Shorthair_Mix</td>\n",
       "      <td>White_Mix</td>\n",
       "      <td>Solid</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Domestic_Shorthair_Mix</td>\n",
       "      <td>Black</td>\n",
       "      <td>Solid</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intake_type intake_condition sex_intake                   breed  \\\n",
       "0            Stray           Normal     Female  Domestic_Shorthair_Mix   \n",
       "1            Stray           Normal       Male                   Other   \n",
       "2            Stray           Normal       Male                   Other   \n",
       "3  Owner_Surrender           Normal     Female  Domestic_Shorthair_Mix   \n",
       "4            Stray           Normal       Male  Domestic_Shorthair_Mix   \n",
       "\n",
       "   CoatColor CoatPattern  age_intake_months  stay_length  intake_type_encoded  \\\n",
       "0      Black       Solid                  1           31                    2   \n",
       "1      Brown       Other                 36            3                    2   \n",
       "2      Brown       Tabby                  1           68                    2   \n",
       "3  White_Mix       Solid                  1           24                    1   \n",
       "4      Black       Solid                  1           30                    2   \n",
       "\n",
       "   intake_condition_encoded  sex_intake_encoded  breed_encoded  \\\n",
       "0                         3                   0              1   \n",
       "1                         3                   1              2   \n",
       "2                         3                   1              2   \n",
       "3                         3                   0              1   \n",
       "4                         3                   1              1   \n",
       "\n",
       "   CoatColor_encoded  CoatPattern_encoded  stay  \n",
       "0                  0                    1     1  \n",
       "1                  3                    0     0  \n",
       "2                  3                    2     1  \n",
       "3                  9                    1     0  \n",
       "4                  0                    1     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of 1: 11157\n",
      "Number of occurrences of 0: 14922\n"
     ]
    }
   ],
   "source": [
    "count_ones = df['stay'].value_counts().get(1)\n",
    "print(f\"Number of occurrences of 1: {count_ones}\")\n",
    "\n",
    "count_zeros = df['stay'].value_counts().get(0)\n",
    "print(f\"Number of occurrences of 0: {count_zeros}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent_variables = ['simplified_color_encoded', 'simplified_sex_encoded',  \n",
    "#                      'simplified_condition_encoded', 'simplified_type_encoded', 'intake_age']\n",
    "\n",
    "# dependent_variable = 'stay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = ['age_intake_months', \n",
    "                     'intake_type_encoded', 'intake_condition_encoded',\n",
    "                     'CoatColor_encoded',  \n",
    "                      'breed_encoded']\n",
    "\n",
    "dependent_variable = 'stay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_intake_months</th>\n",
       "      <th>intake_type_encoded</th>\n",
       "      <th>intake_condition_encoded</th>\n",
       "      <th>CoatColor_encoded</th>\n",
       "      <th>breed_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26074</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26075</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26076</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26077</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26078</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26079 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_intake_months  intake_type_encoded  intake_condition_encoded  \\\n",
       "0                      1                    2                         3   \n",
       "1                     36                    2                         3   \n",
       "2                      1                    2                         3   \n",
       "3                      1                    1                         3   \n",
       "4                      1                    2                         3   \n",
       "...                  ...                  ...                       ...   \n",
       "26074                  1                    2                         3   \n",
       "26075                 11                    2                         3   \n",
       "26076                  0                    2                         2   \n",
       "26077                 36                    1                         3   \n",
       "26078                  1                    2                         3   \n",
       "\n",
       "       CoatColor_encoded  breed_encoded  \n",
       "0                      0              1  \n",
       "1                      3              2  \n",
       "2                      3              2  \n",
       "3                      9              1  \n",
       "4                      0              1  \n",
       "...                  ...            ...  \n",
       "26074                  3              1  \n",
       "26075                  9              0  \n",
       "26076                  3              0  \n",
       "26077                  4              0  \n",
       "26078                  2              0  \n",
       "\n",
       "[26079 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[independent_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18255, 5), (7824, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df[independent_variables]\n",
    "y= df[dependent_variable]\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42) \n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# # Use imbalanced-learn to resample the training data\n",
    "# ros = RandomUnderSampler(sampling_strategy='auto', random_state=42)  # we can adjust the sampling_strategy as needed\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3331"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4493"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 1. Fit your GridSearchCV with your training data. \n",
    "# grid_search_cv.fit(X_resampled, y_resampled)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters it found\n",
    "print(grid_search_cv.best_estimator_) \n",
    "\n",
    "good_model = grid_search_cv.best_estimator_\n",
    "\n",
    "\n",
    "# ----------------------- Now lets evaluate our model------------\n",
    "y_pred = good_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred= y_pred)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred= y_pred)\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred= y_pred)\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = good_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "print('AUC Score: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(good_model.feature_importances_, index=X.columns)\n",
    "feature_importance.sort_values(ascending=False, inplace=True)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratio = (y_test == 1).sum() / ((y_test == 0) | (y_test == 1)).sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_test and y_pred are already defined\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.round(2)\n",
    "\n",
    "# Extract individual elements from the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Greens', fmt='g', cbar=False, ax=ax)\n",
    "\n",
    "# Label the heatmap with TN, FP, FN, and TP values\n",
    "ax.text(0, 0, f'TN: {tn}', ha='center', va='center', color='blue', fontsize=12)\n",
    "ax.text(1, 0, f'FP: {fp}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(0, 1, f'FN: {fn}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 1, f'TP: {tp}', ha='center', va='center', color='blue', fontsize=12)\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¬†ï¸Žâ¬†ï¸Ž-----------  F1 Score: 0.703488 -------- â¬†ï¸Žâ¬†ï¸Ž (best so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "\n",
    "# # Define independent and dependent variables\n",
    "# independent_variables = ['simplified_color_encoded', 'simplified_condition_encoded', 'intake_age']\n",
    "# dependent_variable = 'stay'\n",
    "\n",
    "# # Extract features and target variable\n",
    "# X = df[independent_variables]\n",
    "# y = df[dependent_variable]\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# # Feature Scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Define hyperparameter grid for GridSearchCV\n",
    "# params = { \n",
    "#     'n_estimators': [50, 100, 150],\n",
    "#     'max_features': ['sqrt', 'log2', None],\n",
    "#     'max_depth': [None, 5, 10],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'max_leaf_nodes': [5, 10],\n",
    "#     'class_weight': ['balanced', None]  # Added class_weight to the parameters\n",
    "# }\n",
    "\n",
    "# # Perform GridSearchCV\n",
    "# grid_search_cv = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(),\n",
    "#     param_grid=params,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5, \n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # Fit the model and print the best parameters\n",
    "# grid_search_cv.fit(X_train_scaled, y_train)\n",
    "# print(grid_search_cv.best_estimator_)\n",
    "# good_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = good_model.predict(X_test_scaled)\n",
    "\n",
    "# # Adjust classification threshold\n",
    "# threshold = 0.4  # Adjust based on your needs\n",
    "# y_pred_proba = good_model.predict_proba(X_test_scaled)[:, 1]\n",
    "# y_pred_adjusted = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_adjusted)\n",
    "# precision = precision_score(y_true=y_test, y_pred=y_pred_adjusted)\n",
    "# recall = recall_score(y_true=y_test, y_pred=y_pred_adjusted)\n",
    "# f1 = f1_score(y_true=y_test, y_pred=y_pred_adjusted)\n",
    "# auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "\n",
    "# # Print the evaluation metrics\n",
    "# print(\"Accuracy Score: %f\" % accuracy)\n",
    "# print(\"Precision Score: %f\" % precision)\n",
    "# print(\"Recall Score: %f\" % recall)\n",
    "# print(\"F1 Score: %f\" % f1)\n",
    "# print(\"AUC Score: %f\" % auc)\n",
    "\n",
    "# # Display the adjusted confusion matrix\n",
    "# confusion_mat = confusion_matrix(y_true=y_test, y_pred=y_pred_adjusted)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_mat)\n",
    "\n",
    "# # Experiment with BaggingClassifier\n",
    "# bagging_model = BaggingClassifier(base_estimator=good_model, n_estimators=10, random_state=42)\n",
    "# bagging_scores = cross_val_score(bagging_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "# print(\"Bagging Classifier Cross-Validation Scores:\", bagging_scores)\n",
    "\n",
    "# # Experiment with AdaBoostClassifier\n",
    "# adaboost_model = AdaBoostClassifier(base_estimator=good_model, n_estimators=50, random_state=42)\n",
    "# adaboost_scores = cross_val_score(adaboost_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "# print(\"AdaBoost Classifier Cross-Validation Scores:\", adaboost_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming y_test and y_pred are already defined\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# cm = cm.round(2)\n",
    "\n",
    "# # Extract individual elements from the confusion matrix\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# # Create a figure and axis\n",
    "# fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# # Plot the heatmap\n",
    "# sns.heatmap(cm, annot=True, cmap='Greens', fmt='g', cbar=False, ax=ax)\n",
    "\n",
    "# # Label the heatmap with TN, FP, FN, and TP values\n",
    "# ax.text(0, 0, f'TN: {tn}', ha='center', va='center', color='blue', fontsize=12)\n",
    "# ax.text(1, 0, f'FP: {fp}', ha='center', va='center', color='red', fontsize=12)\n",
    "# ax.text(0, 1, f'FN: {fn}', ha='center', va='center', color='red', fontsize=12)\n",
    "# ax.text(1, 1, f'TP: {tp}', ha='center', va='center', color='blue', fontsize=12)\n",
    "\n",
    "# # Set labels for x and y axes\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "\n",
    "# # Display the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in order to solve the imbalance in calss we use the below code â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Load your dataset\n",
    "df2 = pd.read_csv('../dataset/long_beach_level_encoded_numeric_value_nov_28.csv')\n",
    "\n",
    "# Define the function to categorize stay\n",
    "def categorize_stay(days_stayed):\n",
    "    if days_stayed <= 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply the categorization\n",
    "df2['stay'] = df2['days_stayed'].apply(categorize_stay)\n",
    "\n",
    "independent_variables = ['simplified_color_encoded', 'simplified_condition_encoded', 'intake_age']\n",
    "\n",
    "dependent_variable = 'stay'\n",
    "\n",
    "X = df2[independent_variables]\n",
    "y = df2['stay']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) \n",
    "\n",
    "# Use imbalanced-learn to resample the training data\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)  # You can adjust the sampling_strategy as needed\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Alternatively, you can use RandomUnderSampler for undersampling\n",
    "# rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "# X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV with RandomForestClassifier\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model on the resampled data\n",
    "grid_search_cv.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Print the best parameters it found\n",
    "print(grid_search_cv.best_estimator_) \n",
    "\n",
    "# Extract the best model from GridSearchCV\n",
    "use_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Evaluate the model on the original test set\n",
    "y_pred = use_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = use_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "print('AUC Score: %f' % auc)\n",
    "\n",
    "from joblib import dump\n",
    "dump(use_model, 'use_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(use_model.feature_importances_, index=X.columns)\n",
    "feature_importance.sort_values(ascending=False, inplace=True)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (y_test == 1).sum() / ((y_test == 0) | (y_test == 1)).sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.round(2)\n",
    "\n",
    "# Extract individual elements from the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Greens', fmt='g', cbar=False, ax=ax)\n",
    "\n",
    "# Label the heatmap with TN, FP, FN, and TP values\n",
    "ax.text(0, 0, f'TN: {tn}', ha='center', va='center', color='blue', fontsize=12)\n",
    "ax.text(0, 1, f'FP: {fp}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 0, f'FN: {fn}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 1, f'TP: {tp}', ha='center', va='center', color='blue', fontsize=12)\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¬†ï¸Žâ¬†ï¸Ž-------  F1 Score: 0.627907 ------- â¬†ï¸Žâ¬†ï¸Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using get dummies encoded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../dataset/long_beach_get_dummies_encoded_value_nov_29.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are predicting if a cat will stay more than a month in the shelter (yes = 1, no =0) â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df2['days_stayed']>30).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df2['days_stayed']<30).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is to predict long or short stay (0,1)\n",
    "import pandas as pd\n",
    "\n",
    "def categorize_stay(days_stayed):\n",
    "    if days_stayed <= 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame and \"days_stayed\" is the column you want to categorize\n",
    "df2['stay'] = df2['days_stayed'].apply(categorize_stay)\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ones = df2['stay'].value_counts().get(1)\n",
    "print(f\"Number of occurrences of 1: {count_ones}\")\n",
    "\n",
    "count_zeros = df2['stay'].value_counts().get(0)\n",
    "print(f\"Number of occurrences of 0: {count_zeros}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent_variables = ['simplified_color_encoded', 'simplified_sex_encoded',  \n",
    "#                      'simplified_condition_encoded', 'simplified_type_encoded', 'intake_age']\n",
    "\n",
    "# dependent_variable = 'stay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = ['simplified_color_gray', 'simplified_color_other', 'simplified_color_tabby', 'simplified_color_white', 'simplified_condition_injured', 'simplified_condition_normal', 'simplified_condition_other', 'simplified_condition_under_weight', 'intake_age']\n",
    "dependent_variable = 'stay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent_variables = ['simplified_color_encoded', 'simplified_condition_encoded', 'intake_age']\n",
    "\n",
    "# dependent_variable = 'stay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[independent_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df2[independent_variables]\n",
    "y= df2[dependent_variable]\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) \n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# # Use imbalanced-learn to resample the training data\n",
    "# ros = RandomUnderSampler(sampling_strategy='auto', random_state=42)  # we can adjust the sampling_strategy as needed\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 1. Fit your GridSearchCV with your training data. \n",
    "# grid_search_cv.fit(X_resampled, y_resampled)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters it found\n",
    "print(grid_search_cv.best_estimator_) \n",
    "\n",
    "good_model = grid_search_cv.best_estimator_\n",
    "\n",
    "\n",
    "# ----------------------- Now lets evaluate our model------------\n",
    "y_pred = good_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred= y_pred)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred= y_pred)\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred= y_pred)\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = good_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "print('AUC Score: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(good_model.feature_importances_, index=X.columns)\n",
    "feature_importance.sort_values(ascending=False, inplace=True)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratio = (y_test == 1).sum() / ((y_test == 0) | (y_test == 1)).sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_test and y_pred are already defined\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.round(2)\n",
    "\n",
    "# Extract individual elements from the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Greens', fmt='g', cbar=False, ax=ax)\n",
    "\n",
    "# Label the heatmap with TN, FP, FN, and TP values\n",
    "ax.text(0, 0, f'TN: {tn}', ha='center', va='center', color='blue', fontsize=12)\n",
    "ax.text(1, 0, f'FP: {fp}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(0, 1, f'FN: {fn}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 1, f'TP: {tp}', ha='center', va='center', color='blue', fontsize=12)\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¬†ï¸Žâ¬†ï¸Ž-----------  F1 Score: 0.703488 -------- â¬†ï¸Žâ¬†ï¸Ž "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in order to solve the imbalance in calss we use the below code â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Load your dataset\n",
    "df2 = pd.read_csv('../dataset/long_beach_get_dummies_encoded_value_nov_29.csv')\n",
    "\n",
    "\n",
    "# Define the function to categorize stay\n",
    "def categorize_stay(days_stayed):\n",
    "    if days_stayed <= 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply the categorization\n",
    "df2['stay'] = df2['days_stayed'].apply(categorize_stay)\n",
    "\n",
    "independent_variables = ['simplified_color_gray', 'simplified_color_other', 'simplified_color_tabby', 'simplified_color_white', 'simplified_condition_injured', 'simplified_condition_normal', 'simplified_condition_other', 'simplified_condition_under_weight', 'intake_age']\n",
    "\n",
    "dependent_variable = 'stay'\n",
    "\n",
    "X = df2[independent_variables]\n",
    "y = df2['stay']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# Use imbalanced-learn to resample the training data\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)  # You can adjust the sampling_strategy as needed\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Alternatively, you can use RandomUnderSampler for undersampling\n",
    "# rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "# X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV with RandomForestClassifier\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model on the resampled data\n",
    "grid_search_cv.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Print the best parameters it found\n",
    "print(grid_search_cv.best_estimator_) \n",
    "\n",
    "# Extract the best model from GridSearchCV\n",
    "use_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Evaluate the model on the original test set\n",
    "y_pred = use_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = use_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "print('AUC Score: %f' % auc)\n",
    "\n",
    "from joblib import dump\n",
    "dump(use_model, 'model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(use_model.feature_importances_, index=X.columns)\n",
    "feature_importance.sort_values(ascending=False, inplace=True)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (y_test == 1).sum() / ((y_test == 0) | (y_test == 1)).sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.round(2)\n",
    "\n",
    "# Extract individual elements from the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Greens', fmt='g', cbar=False, ax=ax)\n",
    "\n",
    "# Label the heatmap with TN, FP, FN, and TP values\n",
    "ax.text(0, 0, f'TN: {tn}', ha='center', va='center', color='blue', fontsize=12)\n",
    "ax.text(0, 1, f'FP: {fp}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 0, f'FN: {fn}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 1, f'TP: {tp}', ha='center', va='center', color='blue', fontsize=12)\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¬†ï¸Žâ¬†ï¸Ž-------  F1 Score: 0.627907 ------- â¬†ï¸Žâ¬†ï¸Ž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will try to predict how many month a cat will stay using regression â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month = pd.read_csv('../dataset/long_beach_level_encoded_numeric_value_nov_26.csv')\n",
    "df_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is to predict month stay\n",
    "import pandas as pd\n",
    "\n",
    "def categorize_days(days_stayed):\n",
    "    if days_stayed <= 400:\n",
    "        return np.ceil((days_stayed-15 )/30).astype(int)\n",
    "    \n",
    "# def categorize_days(days_stayed):\n",
    "#     if days_stayed <= 15:\n",
    "#         return 0\n",
    "#     elif days_stayed <= 45:\n",
    "#         return 1\n",
    "#     elif days_stayed <= 75:\n",
    "#         return 2\n",
    "#     elif days_stayed <= 105:\n",
    "#         return 3\n",
    "#     # Add more conditions as needed up to 1200 days\n",
    "#     elif days_stayed <= 1200:\n",
    "#         # Calculate the month based on the provided conditions\n",
    "#         return (days_stayed - 105) // 30 + 3\n",
    "#     else:\n",
    "#         # Handle cases beyond 1200 days if needed\n",
    "#         return 100  # or any other value to indicate an outlier\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame and \"days_stayed\" is the column you want to categorize\n",
    "df_month['months_stayed'] = df_month['days_stayed'].apply(categorize_days)\n",
    "df_month.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['simplified_color_encoded', 'simplified_condition_encoded', 'age']\n",
    "\n",
    "# dependent_variable = 'days_stayed'\n",
    "X= df_month[selected_features]\n",
    "y= df_month['months_stayed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# Using RandomOverSampler to handle imbalanced data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Initialize your GridSearchCV with a RandomForestRegressor, your param_grid, and what you are optimizing for (MSE).\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_grid=params,\n",
    "    scoring='neg_mean_squared_error',  # For regression, use neg_mean_squared_error as the scoring metric.\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit your GridSearchCV with your training data.\n",
    "grid_search_cv.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best estimator based on the mean squared error.\n",
    "best_model = grid_search_cv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score  # Import r2_score\n",
    "\n",
    "# # Map 'class' to binary labels (0 for <=50K and 1 for >50K)\n",
    "# y_binary = (y == ' >50K').astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize the Decision Tree classifier\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "best_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "y_pred = np.round(best_model.predict(X_test))\n",
    "\n",
    "# Specify the positive label\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Mean Squared Error: %f\" % mse)\n",
    "\n",
    "r2 = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"R-squared Score: %f\" % r2)\n",
    "\n",
    "\n",
    "## Eval Model \n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(y_pred)\n",
    "# max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_series is our Pandas Series\n",
    "y_pred_series = pd.Series(y_pred)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_pred_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_test_series is our Pandas Series\n",
    "y_test_series = pd.Series(y_test)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_test_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(y_test.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¬†ï¸Ž----(over sampling) Accuracy Score: 0.036101, R2: -2.728426 ----- â¬†ï¸Ž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with Randomclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month_class = pd.read_csv('../dataset/long_beach_level_encoded_numeric_value_nov_26.csv')\n",
    "df_month_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is to predict month stay\n",
    "import pandas as pd\n",
    "\n",
    "def categorize_days(days_stayed):\n",
    "    if days_stayed <= 300:\n",
    "        return np.ceil((days_stayed-15 )/30).astype(int)\n",
    "    else:\n",
    "        # Handle cases beyond 1200 days if needed\n",
    "        return 99  # or any other value to indicate an outlier\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame and \"days_stayed\" is the column you want to categorize\n",
    "df_month_class['months_stayed'] = df_month_class['days_stayed'].apply(categorize_days)\n",
    "df_month_class.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting each groups frequency\n",
    "grouped_data = df_month_class['months_stayed'].value_counts().sort_index()\n",
    "grouped_data.columns = ['months_stayed', 'Count']\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['simplified_color_encoded', 'simplified_condition_encoded', 'age']\n",
    "\n",
    "# dependent_variable = 'days_stayed'\n",
    "X= df_month_class[selected_features]\n",
    "y= df_month_class['months_stayed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Using RandomOverSampler to handle imbalanced data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Initialize your GridSearchCV with a RandomForestRegressor, your param_grid, and what you are optimizing for (MSE).\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=params,\n",
    "    scoring='neg_mean_squared_error',  # For regression, use neg_mean_squared_error as the scoring metric.\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit your GridSearchCV with your training data.\n",
    "grid_search_cv.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best estimator based on the mean squared error.\n",
    "best_model = grid_search_cv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score  # Import r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit the model\n",
    "best_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average='weighted')  # Adjust average if needed\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average='weighted')  # Adjust average if needed\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')  # Adjust average if needed\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_series is our Pandas Series\n",
    "y_pred_series = pd.Series(y_pred)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_pred_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_series is our Pandas Series\n",
    "y_test_series = pd.Series(y_test)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_test_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------- F1 Score: 0.013658 ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd approch (all code together) RandomForestRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Load the dataset\n",
    "df_month_short = pd.read_csv('../dataset/long_beach_level_encoded_numeric_value_nov_26.csv')\n",
    "\n",
    "# Define a function to categorize days\n",
    "def categorize_days(days_stayed):\n",
    "    if days_stayed <= 300:\n",
    "        return np.ceil((days_stayed - 15) / 30).astype(int)\n",
    "    else:\n",
    "        return 99  # or any other value to indicate an outlier\n",
    "\n",
    "# Apply the categorization to create a new column 'months_stayed'\n",
    "df_month_short['months_stayed'] = df_month_short['days_stayed'].apply(categorize_days)\n",
    "\n",
    "# Define selected features\n",
    "selected_features = ['simplified_color_encoded',  \n",
    "                     'simplified_condition_encoded', 'age']\n",
    "\n",
    "# Set up X and y\n",
    "X = df_month_short[selected_features]\n",
    "y = df_month_short['months_stayed']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomUnderSampler\n",
    "rus = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_grid=params,\n",
    "    scoring='f1_weighted',  # Use F1 score for classification and consider class imbalance\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV with resampled training data\n",
    "grid_search_cv.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best estimator based on F1 score\n",
    "best_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Fit the best model with the original training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "print(\"F1 Score: %f\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(best_model.feature_importances_, index=X.columns)\n",
    "feature_importance.sort_values(ascending=False, inplace=True)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"MAE: {mae}, MSE: {mse}, RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(y_pred)\n",
    "# max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with residuals\n",
    "residuals_df = pd.DataFrame({'True Values': y_test, 'Predicted Values': y_pred, 'Residuals': residuals})\n",
    "\n",
    "# Sort the DataFrame by residuals in ascending order\n",
    "residuals_df_sorted = residuals_df.sort_values(by='Residuals', ascending=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(\"Sorted by Residuals (Ascending):\")\n",
    "print(residuals_df_sorted.head(50))\n",
    "\n",
    "# Sort the DataFrame by residuals in descending order\n",
    "residuals_df_sorted_desc = residuals_df.sort_values(by='Residuals', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(\"Sorted by Residuals (Descending):\")\n",
    "print(residuals_df_sorted_desc.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(residuals_df_sorted_desc[residuals_df_sorted_desc['Residuals']==0].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of residuals\n",
    "plt.hist(residuals_df['Residuals'], bins=20, edgecolor='black')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_series is our Pandas Series\n",
    "y_pred_series = pd.Series(y_pred)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_pred_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_test_series is our Pandas Series\n",
    "y_test_series = pd.Series(y_test)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_test_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¬†ï¸Žâ¬†ï¸Ž---------(Over sampling) F1 Score: 0.129868 -----â¬†ï¸Žâ¬†ï¸Ž"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
