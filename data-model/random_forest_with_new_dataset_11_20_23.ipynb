{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our libraries \n",
    "\n",
    "# Pandas and numpy for data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Seaborn / matplotlib for visualization \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function to split our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Helper fuctions to evaluate our model.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "\n",
    "# Import our Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# Import our Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import the trees from sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "# Helper functions to visualize our trees\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "\n",
    "#tree regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Size</th>\n",
       "      <th>Animal ID</th>\n",
       "      <th>Intake Date</th>\n",
       "      <th>Outcome Date</th>\n",
       "      <th>Days in Shelter</th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Outcome Condition</th>\n",
       "      <th>Age</th>\n",
       "      <th>Color_encoded</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Intake Condition_encoded</th>\n",
       "      <th>Intake Type_encoded</th>\n",
       "      <th>Breed_encoded</th>\n",
       "      <th>Size_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC LH</td>\n",
       "      <td>BLACK/WHITE</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>A420773</td>\n",
       "      <td>09/29/2023</td>\n",
       "      <td>09/30/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>RETURN TO OWNER</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>ORG TABBY/WHITE</td>\n",
       "      <td>Spayed</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A417889</td>\n",
       "      <td>05/30/2023</td>\n",
       "      <td>08/08/2023</td>\n",
       "      <td>70</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>ADOPTION</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A418221</td>\n",
       "      <td>06/13/2023</td>\n",
       "      <td>08/08/2023</td>\n",
       "      <td>56</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>ADOPTION</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAT</td>\n",
       "      <td>SIAMESE/MIX</td>\n",
       "      <td>LYNX PT</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A420264</td>\n",
       "      <td>09/12/2023</td>\n",
       "      <td>09/30/2023</td>\n",
       "      <td>18</td>\n",
       "      <td>OWNER SURRENDER</td>\n",
       "      <td>ADOPTION</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A419416</td>\n",
       "      <td>08/01/2023</td>\n",
       "      <td>09/30/2023</td>\n",
       "      <td>60</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>ADOPTION</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type        Breed            Color       Sex   Size Animal ID Intake Date  \\\n",
       "0  CAT  DOMESTIC LH      BLACK/WHITE  Neutered  SMALL   A420773  09/29/2023   \n",
       "1  CAT  DOMESTIC SH  ORG TABBY/WHITE    Spayed  KITTN   A417889  05/30/2023   \n",
       "2  CAT  DOMESTIC SH            BLACK  Neutered  KITTN   A418221  06/13/2023   \n",
       "3  CAT  SIAMESE/MIX          LYNX PT  Neutered  KITTN   A420264  09/12/2023   \n",
       "4  CAT  DOMESTIC SH            BLACK  Neutered  KITTN   A419416  08/01/2023   \n",
       "\n",
       "  Outcome Date  Days in Shelter      Intake Type     Outcome Type  \\\n",
       "0   09/30/2023                1            STRAY  RETURN TO OWNER   \n",
       "1   08/08/2023               70            STRAY         ADOPTION   \n",
       "2   08/08/2023               56            STRAY         ADOPTION   \n",
       "3   09/30/2023               18  OWNER SURRENDER         ADOPTION   \n",
       "4   09/30/2023               60            STRAY         ADOPTION   \n",
       "\n",
       "  Intake Condition Outcome Condition  Age  Color_encoded  Sex_encoded  \\\n",
       "0          HEALTHY           HEALTHY   10              1            2   \n",
       "1          UNKNOWN           HEALTHY    0             22            3   \n",
       "2          UNKNOWN           HEALTHY    0              0            2   \n",
       "3          HEALTHY           HEALTHY    0             18            2   \n",
       "4          UNKNOWN           HEALTHY    0              0            2   \n",
       "\n",
       "   Intake Condition_encoded  Intake Type_encoded  Breed_encoded  Size_encoded  \n",
       "0                         0                    5              8             3  \n",
       "1                         3                    5             13             0  \n",
       "2                         3                    5             13             0  \n",
       "3                         0                    3             34             0  \n",
       "4                         3                    5             13             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/encoded_dataset_nov_17.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are predicting if a cat will stay more than a month in the shelter (yes = 1, no =0) â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Days in Shelter']>60).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4305"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Days in Shelter']<60).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Size</th>\n",
       "      <th>Animal ID</th>\n",
       "      <th>Intake Date</th>\n",
       "      <th>Outcome Date</th>\n",
       "      <th>Days in Shelter</th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Outcome Condition</th>\n",
       "      <th>Age</th>\n",
       "      <th>Color_encoded</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Intake Condition_encoded</th>\n",
       "      <th>Intake Type_encoded</th>\n",
       "      <th>Breed_encoded</th>\n",
       "      <th>Size_encoded</th>\n",
       "      <th>stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>MED</td>\n",
       "      <td>A319435</td>\n",
       "      <td>02/03/2016</td>\n",
       "      <td>02/19/2016</td>\n",
       "      <td>16</td>\n",
       "      <td>OWNER SURRENDER</td>\n",
       "      <td>...</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>BRN TABBY/WHITE</td>\n",
       "      <td>Spayed</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A413165</td>\n",
       "      <td>09/15/2022</td>\n",
       "      <td>10/29/2022</td>\n",
       "      <td>44</td>\n",
       "      <td>OWNER SURRENDER</td>\n",
       "      <td>...</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>WHITE/BLACK</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A389577</td>\n",
       "      <td>07/20/2019</td>\n",
       "      <td>07/30/2019</td>\n",
       "      <td>10</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>...</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>BRN TABBY/WHITE</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>A310168</td>\n",
       "      <td>08/14/2014</td>\n",
       "      <td>08/23/2014</td>\n",
       "      <td>9</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>BLUE CREAM</td>\n",
       "      <td>Spayed</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A412870</td>\n",
       "      <td>08/16/2022</td>\n",
       "      <td>09/29/2022</td>\n",
       "      <td>44</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type        Breed            Color       Sex   Size Animal ID  \\\n",
       "4744  CAT  DOMESTIC SH            BLACK  Neutered    MED   A319435   \n",
       "4745  CAT  DOMESTIC SH  BRN TABBY/WHITE    Spayed  KITTN   A413165   \n",
       "4746  CAT  DOMESTIC SH      WHITE/BLACK  Neutered  KITTN   A389577   \n",
       "4747  CAT  DOMESTIC SH  BRN TABBY/WHITE  Neutered  SMALL   A310168   \n",
       "4748  CAT  DOMESTIC SH       BLUE CREAM    Spayed  KITTN   A412870   \n",
       "\n",
       "     Intake Date Outcome Date  Days in Shelter      Intake Type  ...  \\\n",
       "4744  02/03/2016   02/19/2016               16  OWNER SURRENDER  ...   \n",
       "4745  09/15/2022   10/29/2022               44  OWNER SURRENDER  ...   \n",
       "4746  07/20/2019   07/30/2019               10         TRANSFER  ...   \n",
       "4747  08/14/2014   08/23/2014                9            STRAY  ...   \n",
       "4748  08/16/2022   09/29/2022               44            STRAY  ...   \n",
       "\n",
       "     Intake Condition Outcome Condition Age  Color_encoded  Sex_encoded  \\\n",
       "4744          HEALTHY           HEALTHY   9              0            2   \n",
       "4745          HEALTHY           HEALTHY   1              8            3   \n",
       "4746          HEALTHY           HEALTHY   4             26            2   \n",
       "4747          HEALTHY           HEALTHY   9              8            2   \n",
       "4748          HEALTHY           HEALTHY   1              4            3   \n",
       "\n",
       "      Intake Condition_encoded  Intake Type_encoded  Breed_encoded  \\\n",
       "4744                         0                    3             13   \n",
       "4745                         0                    3             13   \n",
       "4746                         0                    6             13   \n",
       "4747                         0                    5             13   \n",
       "4748                         0                    5             13   \n",
       "\n",
       "      Size_encoded  stay  \n",
       "4744             2     0  \n",
       "4745             0     0  \n",
       "4746             0     0  \n",
       "4747             3     0  \n",
       "4748             0     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this part is to predict long or short stay (0,1)\n",
    "import pandas as pd\n",
    "\n",
    "def categorize_stay(days_stayed):\n",
    "    if days_stayed <= 60:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame and \"days_stayed\" is the column you want to categorize\n",
    "df['stay'] = df['Days in Shelter'].apply(categorize_stay)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Size</th>\n",
       "      <th>Animal ID</th>\n",
       "      <th>Intake Date</th>\n",
       "      <th>Outcome Date</th>\n",
       "      <th>Days in Shelter</th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Outcome Condition</th>\n",
       "      <th>Age</th>\n",
       "      <th>Color_encoded</th>\n",
       "      <th>Sex_encoded</th>\n",
       "      <th>Intake Condition_encoded</th>\n",
       "      <th>Intake Type_encoded</th>\n",
       "      <th>Breed_encoded</th>\n",
       "      <th>Size_encoded</th>\n",
       "      <th>stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC LH</td>\n",
       "      <td>BLACK/WHITE</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>A420773</td>\n",
       "      <td>09/29/2023</td>\n",
       "      <td>09/30/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>ORG TABBY/WHITE</td>\n",
       "      <td>Spayed</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A417889</td>\n",
       "      <td>05/30/2023</td>\n",
       "      <td>08/08/2023</td>\n",
       "      <td>70</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A418221</td>\n",
       "      <td>06/13/2023</td>\n",
       "      <td>08/08/2023</td>\n",
       "      <td>56</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAT</td>\n",
       "      <td>SIAMESE/MIX</td>\n",
       "      <td>LYNX PT</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A420264</td>\n",
       "      <td>09/12/2023</td>\n",
       "      <td>09/30/2023</td>\n",
       "      <td>18</td>\n",
       "      <td>OWNER SURRENDER</td>\n",
       "      <td>...</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAT</td>\n",
       "      <td>DOMESTIC SH</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>KITTN</td>\n",
       "      <td>A419416</td>\n",
       "      <td>08/01/2023</td>\n",
       "      <td>09/30/2023</td>\n",
       "      <td>60</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type        Breed            Color       Sex   Size Animal ID Intake Date  \\\n",
       "0  CAT  DOMESTIC LH      BLACK/WHITE  Neutered  SMALL   A420773  09/29/2023   \n",
       "1  CAT  DOMESTIC SH  ORG TABBY/WHITE    Spayed  KITTN   A417889  05/30/2023   \n",
       "2  CAT  DOMESTIC SH            BLACK  Neutered  KITTN   A418221  06/13/2023   \n",
       "3  CAT  SIAMESE/MIX          LYNX PT  Neutered  KITTN   A420264  09/12/2023   \n",
       "4  CAT  DOMESTIC SH            BLACK  Neutered  KITTN   A419416  08/01/2023   \n",
       "\n",
       "  Outcome Date  Days in Shelter      Intake Type  ... Intake Condition  \\\n",
       "0   09/30/2023                1            STRAY  ...          HEALTHY   \n",
       "1   08/08/2023               70            STRAY  ...          UNKNOWN   \n",
       "2   08/08/2023               56            STRAY  ...          UNKNOWN   \n",
       "3   09/30/2023               18  OWNER SURRENDER  ...          HEALTHY   \n",
       "4   09/30/2023               60            STRAY  ...          UNKNOWN   \n",
       "\n",
       "  Outcome Condition Age  Color_encoded  Sex_encoded  Intake Condition_encoded  \\\n",
       "0           HEALTHY  10              1            2                         0   \n",
       "1           HEALTHY   0             22            3                         3   \n",
       "2           HEALTHY   0              0            2                         3   \n",
       "3           HEALTHY   0             18            2                         0   \n",
       "4           HEALTHY   0              0            2                         3   \n",
       "\n",
       "   Intake Type_encoded  Breed_encoded  Size_encoded  stay  \n",
       "0                    5              8             3     0  \n",
       "1                    5             13             0     1  \n",
       "2                    5             13             0     0  \n",
       "3                    3             34             0     0  \n",
       "4                    5             13             0     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurrences of 1: 423\n",
      "Number of occurrences of 0: 4326\n"
     ]
    }
   ],
   "source": [
    "count_ones = df['stay'].value_counts().get(1)\n",
    "print(f\"Number of occurrences of 1: {count_ones}\")\n",
    "\n",
    "count_zeros = df['stay'].value_counts().get(0)\n",
    "print(f\"Number of occurrences of 0: {count_zeros}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = ['Color_encoded', 'Sex_encoded',  \n",
    "                     'Intake Condition_encoded', 'Intake Type_encoded']\n",
    "\n",
    "dependent_variable = 'stay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2236, 4), (746, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df[independent_variables]\n",
    "y= df['stay']\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) \n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m\n\u001b[1;32m      9\u001b[0m grid_search_cv \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     10\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mRandomForestClassifier(),\n\u001b[1;32m     11\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 1. Fit your GridSearchCV with your training data. \u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m grid_search_cv\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Print the best parameters it found\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_search_cv\u001b[38;5;241m.\u001b[39mbest_estimator_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:177\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m    178\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;66;03m# Need to validate separately here.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;66;03m# We can't pass multi_output=True because that would allow y to be\u001b[39;00m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;66;03m# csr.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:602\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    593\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_constraints,\n\u001b[0;32m--> 602\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    603\u001b[0m         caller_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    604\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:169\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03mGet parameters for this estimator.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    Parameter names mapped to their values.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[1;32m    170\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:134\u001b[0m, in \u001b[0;36mBaseEstimator._get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# introspect the constructor arguments to find the model parameters\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# to represent\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m init_signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(init)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Consider the constructor parameters excluding 'self'\u001b[39;00m\n\u001b[1;32m    136\u001b[0m parameters \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    137\u001b[0m     p\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m init_signature\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m p\u001b[38;5;241m.\u001b[39mVAR_KEYWORD\n\u001b[1;32m    140\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/inspect.py:3278\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3273\u001b[0m             rendered \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(anno)\n\u001b[1;32m   3275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m rendered\n\u001b[0;32m-> 3278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[1;32m   3280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Signature\u001b[38;5;241m.\u001b[39mfrom_callable(obj, follow_wrapped\u001b[38;5;241m=\u001b[39mfollow_wrapped,\n\u001b[1;32m   3281\u001b[0m                                    \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 1. Fit your GridSearchCV with your training data. \n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters it found\n",
    "print(grid_search_cv.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = grid_search_cv.best_estimator_\n",
    "\n",
    "\n",
    "# Now lets evaluate our model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred= y_pred)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred= y_pred)\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred= y_pred)\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "print('AUC Score: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratio = (y_test == 1).sum() / ((y_test == 0) | (y_test == 1)).sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_test and y_pred are already defined\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.round(2)\n",
    "\n",
    "# Extract individual elements from the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Greens', fmt='g', cbar=False, ax=ax)\n",
    "\n",
    "# Label the heatmap with TN, FP, FN, and TP values\n",
    "ax.text(0, 0, f'TN: {tn}', ha='center', va='center', color='blue', fontsize=12)\n",
    "ax.text(0, 1, f'FP: {fp}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 0, f'FN: {fn}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 1, f'TP: {tp}', ha='center', va='center', color='blue', fontsize=12)\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¬†ï¸Žâ¬†ï¸Ž-----------  F1 Score: 0.677930 -------- â¬†ï¸Žâ¬†ï¸Ž (best so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in order to solve the imbalance in calss we use the below code â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Load your dataset\n",
    "df2 = pd.read_csv('../dataset/df_only_numeric_value_nov_05.csv')\n",
    "\n",
    "# Define the function to categorize stay\n",
    "def categorize_stay(days_stayed):\n",
    "    if days_stayed <= 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply the categorization\n",
    "df2['stay'] = df2['days_stayed'].apply(categorize_stay)\n",
    "\n",
    "independent_variables = ['Primary_Color_encoded', 'Sex_encoded',  \n",
    "                     'Intake_Condition_encoded', 'Intake_Type_encoded']\n",
    "\n",
    "dependent_variable = 'stay'\n",
    "\n",
    "X = df2[independent_variables]\n",
    "y = df2['stay']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) \n",
    "\n",
    "# Use imbalanced-learn to resample the training data\n",
    "# ros = RandomOverSampler(sampling_strategy='auto', random_state=42)  # You can adjust the sampling_strategy as needed\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Alternatively, you can use RandomUnderSampler for undersampling\n",
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV with RandomForestClassifier\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model on the resampled data\n",
    "grid_search_cv.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Print the best parameters it found\n",
    "print(grid_search_cv.best_estimator_) \n",
    "\n",
    "# Extract the best model from GridSearchCV\n",
    "model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Evaluate the model on the original test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "print('AUC Score: %f' % auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (y_test == 1).sum() / ((y_test == 0) | (y_test == 1)).sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.round(2)\n",
    "\n",
    "# Extract individual elements from the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Greens', fmt='g', cbar=False, ax=ax)\n",
    "\n",
    "# Label the heatmap with TN, FP, FN, and TP values\n",
    "ax.text(0, 0, f'TN: {tn}', ha='center', va='center', color='blue', fontsize=12)\n",
    "ax.text(0, 1, f'FP: {fp}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 0, f'FN: {fn}', ha='center', va='center', color='red', fontsize=12)\n",
    "ax.text(1, 1, f'TP: {tp}', ha='center', va='center', color='blue', fontsize=12)\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¬†ï¸Žâ¬†ï¸Ž-------  F1 Score: 0.630460 ------- â¬†ï¸Žâ¬†ï¸Ž(2nd best so far)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will try to predict how many month a cat will stay using regression â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month = pd.read_csv('../dataset/df_only_numeric_value_nov_05.csv')\n",
    "df_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is to predict month stay\n",
    "import pandas as pd\n",
    "\n",
    "def categorize_days(days_stayed):\n",
    "    if days_stayed <= 15:\n",
    "        return 0\n",
    "    elif days_stayed <= 45:\n",
    "        return 1\n",
    "    elif days_stayed <= 75:\n",
    "        return 2\n",
    "    elif days_stayed <= 105:\n",
    "        return 3\n",
    "    # Add more conditions as needed up to 1200 days\n",
    "    elif days_stayed <= 1200:\n",
    "        # Calculate the month based on the provided conditions\n",
    "        return (days_stayed - 105) // 30 + 3\n",
    "#     else:\n",
    "#         # Handle cases beyond 1200 days if needed\n",
    "#         return 100  # or any other value to indicate an outlier\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame and \"days_stayed\" is the column you want to categorize\n",
    "df_month['months_stayed'] = df_month['days_stayed'].apply(categorize_days)\n",
    "df_month.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Primary_Color_encoded', 'Sex_encoded',  \n",
    "                     'Intake_Condition_encoded', 'Intake_Type_encoded']\n",
    "\n",
    "# dependent_variable = 'days_stayed'\n",
    "X= df_month[selected_features]\n",
    "y= df_month['months_stayed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Initialize your GridSearchCV with a RandomForestRegressor, your param_grid, and what you are optimizing for (MSE).\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_grid=params,\n",
    "    scoring='neg_mean_squared_error',  # For regression, use neg_mean_squared_error as the scoring metric.\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit your GridSearchCV with your training data.\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator based on the mean squared error.\n",
    "best_model = grid_search_cv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score  # Import r2_score\n",
    "\n",
    "# # Map 'class' to binary labels (0 for <=50K and 1 for >50K)\n",
    "# y_binary = (y == ' >50K').astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize the Decision Tree classifier\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "y_pred = np.round(best_model.predict(X_test))\n",
    "\n",
    "# Specify the positive label\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Mean Squared Error: %f\" % mse)\n",
    "\n",
    "r2 = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"R-squared Score: %f\" % r2)\n",
    "\n",
    "## Eval Model \n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(y_pred)\n",
    "# max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_series is our Pandas Series\n",
    "y_pred_series = pd.Series(y_pred)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_pred_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_test_series is our Pandas Series\n",
    "y_test_series = pd.Series(y_test)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_test_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(y_test.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ Accuracy Score: 0.180905 --------- (4th best so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with Randomclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month_short = pd.read_csv('../dataset/df_only_numeric_value_nov_05.csv')\n",
    "df_month_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is to predict month stay\n",
    "import pandas as pd\n",
    "\n",
    "def categorize_days(days_stayed):\n",
    "    if days_stayed <= 285:\n",
    "        return np.ceil((days_stayed-15 )/30).astype(int)\n",
    "    else:\n",
    "        # Handle cases beyond 1200 days if needed\n",
    "        return 99  # or any other value to indicate an outlier\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame and \"days_stayed\" is the column you want to categorize\n",
    "df_month_short['months_stayed'] = df_month_short['days_stayed'].apply(categorize_days)\n",
    "df_month_short.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting each groups frequency\n",
    "grouped_data = df_month_short['months_stayed'].value_counts().sort_index()\n",
    "grouped_data.columns = ['months_stayed', 'Count']\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Primary_Color_encoded', 'Sex_encoded',  \n",
    "                     'Intake_Condition_encoded', 'Intake_Type_encoded']\n",
    "\n",
    "# dependent_variable = 'days_stayed'\n",
    "X= df_month[selected_features]\n",
    "y= df_month['months_stayed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Initialize your GridSearchCV with a RandomForestRegressor, your param_grid, and what you are optimizing for (MSE).\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=params,\n",
    "    scoring='neg_mean_squared_error',  # For regression, use neg_mean_squared_error as the scoring metric.\n",
    "    cv=5, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit your GridSearchCV with your training data.\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator based on the mean squared error.\n",
    "best_model = grid_search_cv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score  # Import r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit the model\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average='weighted')  # Adjust average if needed\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, average='weighted')  # Adjust average if needed\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')  # Adjust average if needed\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------- F1 Score: 0.260524 ------------ (3rd best so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd approch (all code together) RandomForestRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Load the dataset\n",
    "df_month_short = pd.read_csv('../dataset/df_only_numeric_value_nov_05.csv')\n",
    "\n",
    "# Define a function to categorize days\n",
    "def categorize_days(days_stayed):\n",
    "    if days_stayed <= 285:\n",
    "        return np.ceil((days_stayed - 15) / 30).astype(int)\n",
    "    else:\n",
    "        return 99  # or any other value to indicate an outlier\n",
    "\n",
    "# Apply the categorization to create a new column 'months_stayed'\n",
    "df_month_short['months_stayed'] = df_month_short['days_stayed'].apply(categorize_days)\n",
    "\n",
    "# Define selected features\n",
    "selected_features = ['Primary_Color_encoded', 'Sex_encoded',\n",
    "                     'Intake_Condition_encoded', 'Intake_Type_encoded']\n",
    "\n",
    "# Set up X and y\n",
    "X = df_month_short[selected_features]\n",
    "y = df_month_short['months_stayed']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',  # Use accuracy for classification\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV with resampled training data\n",
    "grid_search_cv.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best estimator based on accuracy\n",
    "best_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Fit the best model with resampled training data\n",
    "best_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "print(\"F1 Score: %f\" % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(y_pred)\n",
    "# max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_series is our Pandas Series\n",
    "y_pred_series = pd.Series(y_pred)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_pred_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_test_series is our Pandas Series\n",
    "y_test_series = pd.Series(y_test)\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = y_test_series.value_counts()\n",
    "\n",
    "# Sort the values based on unique values\n",
    "sorted_value_counts = value_counts.sort_index()\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"Sorted Value Counts:\")\n",
    "print(sorted_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(y_test.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------- F1 Score: 0.142566 ------------ (worst so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The below part has error â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[independent_variables]\n",
    "# y = df[dependent_variable]\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Parameter grid for GridSearchCV\n",
    "# params = { \n",
    "#     'n_estimators': [50, 100, 150],\n",
    "#     'max_features': ['sqrt', 'log2', None],\n",
    "#     'max_depth': [None, 5, 10],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'max_leaf_nodes': [5, 10]\n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV with RandomForestClassifier\n",
    "# grid_search_cv = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(random_state=42),\n",
    "#     param_grid=params,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5, \n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # Fit GridSearchCV with training data\n",
    "# grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best estimator based on accuracy\n",
    "# best_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the best model\n",
    "# accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "# precision = precision_score(y_true=y_test, y_pred=y_pred, zero_division=1)\n",
    "# recall = recall_score(y_true=y_test, y_pred=y_pred, zero_division=1)\n",
    "# f1 = f1_score(y_true=y_test, y_pred=y_pred, zero_division=1)\n",
    "\n",
    "# print(\"Accuracy Score: %f\" % accuracy)\n",
    "# print(\"Precision Score: %f\" % precision)\n",
    "# print(\"Recall Score: %f\" % recall)\n",
    "# print('F1 Score: %f' % f1)\n",
    "\n",
    "# # Calculate predicted probabilities for the positive class\n",
    "# y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # Calculate AUC score\n",
    "# auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "# print('AUC Score: %f' % auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The below part I kept for only reference purposes, no use here at this moment â˜Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = RandomForestClassifier()\n",
    "# X = df[independent_variables]\n",
    "# y = df[dependent_variable]\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# # Fit the model to the training data\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Now let's evaluate our model on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Now lets evaluate our model\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# ## Eval Model \n",
    "# accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "# print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "# precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "# print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "# recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "# print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "# f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "# print('F1 Score: %f' % f1)\n",
    "\n",
    "# # Calculate predicted probabilities\n",
    "# y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# # # Keep only the proba for True\n",
    "# y_pred_proba = y_pred_proba[:,1]\n",
    "\n",
    "# # Compute auc score\n",
    "# auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "# print('AUC Score: %f' % auc)\n",
    "\n",
    "\n",
    "# # Produce classification Report\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------ignore the below part for now -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = OneVsRestClassifier(DecisionTreeClassifier(max_depth=2))\n",
    "\n",
    "# X = df[independent_variables]\n",
    "# y = df[dependent_variable]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Eval Model\n",
    "# accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "# print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "# precision = precision_score(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "# print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "# recall = recall_score(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "# print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "# f1 = f1_score(y_true=y_test, y_pred=y_pred, average='micro')\n",
    "# print('F1 Score: %f' % f1)\n",
    "\n",
    "# # Calculate predicted probabilities\n",
    "# y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# # Keep only the proba for True\n",
    "# y_pred_proba = y_pred_proba[:, 1]\n",
    "\n",
    "# # Compute auc score\n",
    "# auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "# print('AUC Score: %f' % auc)\n",
    "\n",
    "# # Produce classification Report\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Plot Tree\n",
    "# # Note: Plotting trees for multi-class problems can be complex and may not provide clear visualizations\n",
    "# # You may want to visualize individual trees if you're dealing with a smaller number of classes\n",
    "# class_names = df[dependent_variable].unique()\n",
    "# plot_tree(model.estimators_[0], feature_names=independent_variables, class_names=class_names, filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize a Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=100)  # You can adjust the number of estimators as needed\n",
    "\n",
    "X = df[independent_variables]\n",
    "y = df[dependent_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Now let's evaluate our model on the test set\n",
    "y_pred = model.predict(X_test).round().astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Mean Squared Error: %f\" % mse)\n",
    "\n",
    "r2 = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"R-squared Score: %f\" % r2)\n",
    "\n",
    "## Eval Model \n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets look at our feature importances\n",
    "feature_imp = pd.Series(model.feature_importances_,index=independent_variables).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    # Add more hyperparameters to tune\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best hyperparameters to train the model\n",
    "best_model = RandomForestClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_model.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract one decision tree from the random forest (e.g., the first tree)\n",
    "one_tree = model.estimators_[0]\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(one_tree, feature_names=independent_variables, class_names=class_names, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sami trying here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Your feature and target variable definitions\n",
    "selected_features = ['Primary_Color_encoded', 'Sex_encoded', 'Intake_Condition_encoded', 'Intake_Type_encoded']\n",
    "X = df[selected_features]\n",
    "y = df['days_stayed']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with RandomForestRegressor\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_grid=params,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV with training data\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator based on mean squared error\n",
    "best_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Make predictions using the best model\n",
    "y_pred = np.round(best_model.predict(X_test))\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Mean Squared Error: %f\" % mse)\n",
    "\n",
    "r2 = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"R-squared Score: %f\" % r2)\n",
    "\n",
    "# Additional evaluation metrics if needed\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# ... (your data loading and preprocessing code)\n",
    "# Your feature and target variable definitions\n",
    "selected_features = ['Primary_Color_encoded', 'Sex_encoded', 'Intake_Condition_encoded', 'Intake_Type_encoded']\n",
    "X = df[selected_features]\n",
    "y = df['days_stayed']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# New hyperparameter grid\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_leaf_nodes': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# GridSearchCV with RandomForestRegressor\n",
    "grid_search_cv_rf = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_grid=params,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# GridSearchCV with GradientBoostingRegressor\n",
    "grid_search_cv_gb = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(),\n",
    "    param_grid=params,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# GridSearchCV with LinearRegression\n",
    "grid_search_cv_lr = GridSearchCV(\n",
    "    estimator=LinearRegression(),\n",
    "    param_grid={},\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# GridSearchCV with SVR\n",
    "grid_search_cv_svr = GridSearchCV(\n",
    "    estimator=SVR(),\n",
    "    param_grid={'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit models\n",
    "grid_search_cv_rf.fit(X_train, y_train)\n",
    "grid_search_cv_gb.fit(X_train, y_train)\n",
    "grid_search_cv_lr.fit(X_train, y_train)\n",
    "grid_search_cv_svr.fit(X_train, y_train)\n",
    "\n",
    "# Get best models\n",
    "best_rf_model = grid_search_cv_rf.best_estimator_\n",
    "best_gb_model = grid_search_cv_gb.best_estimator_\n",
    "best_lr_model = grid_search_cv_lr.best_estimator_\n",
    "best_svr_model = grid_search_cv_svr.best_estimator_\n",
    "\n",
    "# Evaluate models\n",
    "models = [best_rf_model, best_gb_model, best_lr_model, best_svr_model]\n",
    "model_names = ['RandomForestRegressor', 'GradientBoostingRegressor', 'LinearRegression', 'SVR']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    y_pred = np.round(model.predict(X_test))\n",
    "    mse = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "    r2 = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "    print(f\"{name} - Mean Squared Error: {mse}, R-squared Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
